{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Federated learning**\n",
        "\n",
        "Federated learning is a new paradigm in machine learning that allows the training of models on data from multiple sources without having to share the data. This is particularly important in scenarios where data privacy is a concern or where it is difficult to gather all the data in one place. This is a simple implementation of federated learning on MNIST data."
      ],
      "metadata": {
        "id": "wpKUZBIs5ZSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoZStUu1e4FF"
      },
      "outputs": [],
      "source": [
        " # Import relevant packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "# Reshape the data to add a channel dimension (required for convolutional layers)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n"
      ],
      "metadata": {
        "id": "v41-tE-VjRYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[1]) # showing the data image\n"
      ],
      "metadata": {
        "id": "eINVMvxno_Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Model"
      ],
      "metadata": {
        "id": "riuQuudHjfGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN is used for digit classification\n",
        "# Define the model architecture\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        # Convolutional layer with 32 filters, a 3x3 filter size, and ReLU activation function\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        # Max pooling layer with a 2x2 pool size\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        # Add an other Convolutional layer with 64 filters, a 3x3 filter size, and ReLU activation function\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "         # Add an other Max pooling layer with a 2x2 pool size\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        # Add an other Convolutional layer with 128 filters, a 3x3 filter size, and ReLU activation function\n",
        "        keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "         # Add an other Max pooling layer with a 2x2 pool size\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        # Flatten the output of the convolutional layers to prepare it for the dense layers\n",
        "        keras.layers.Flatten(),\n",
        "         # Add a dense layer with 128 units and ReLU activation function\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        # Add a dropout layer to prevent overfitting\n",
        "        keras.layers.Dropout(0.5),\n",
        "        # Output layer, this corresponds to a multiclass classification (softmax activation function) problem (output is from 0 to 9)\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "dmstKmRax-fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simulating the Federated Learning Environment**\n",
        "\n",
        " To simulate the FL environment. We assume that there are three parties involved in the FL process, each with its own dataset. We randomly split the MNIST dataset into three parts and simulate the training process for each party."
      ],
      "metadata": {
        "id": "lv_ttJL_kw_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate the federated learning process\n",
        "def federated_train(model, train_data, train_labels, test_data, test_labels, epochs, lr):\n",
        "    for epoch in range(epochs):\n",
        "        # Shuffle the data for each epoch\n",
        "        indices = np.random.permutation(len(train_data))\n",
        "        train_data = train_data[indices]\n",
        "        train_labels = train_labels[indices]\n",
        "\n",
        "        # Simulate the federated learning process for each party\n",
        "        for party_id in range(3):\n",
        "            # Get the local data and labels for the party\n",
        "            party_data = train_data[party_id * (len(train_data) // 3):(party_id + 1) * (len(train_data) // 3)]\n",
        "            party_labels = train_labels[party_id * (len(train_data) // 3):(party_id + 1) * (len(train_data) // 3)]\n",
        "\n",
        "            # Train the local model\n",
        "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            model.fit(party_data, party_labels, epochs=1, verbose=0)\n",
        "\n",
        "        # Evaluate the model on the test data\n",
        "        test_loss, test_acc = model.evaluate(test_data, test_labels, verbose=0)\n",
        "\n",
        "        print('Epoch', epoch + 1, '- Test loss:', test_loss, '- Test accuracy:', test_acc)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "IESru1xlwIeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters for the federated learning process\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Simulate the federated learning process\n",
        "model = create_model()\n",
        "model = federated_train(model, train_data, train_labels, test_data, test_labels, num_epochs, learning_rate)\n"
      ],
      "metadata": {
        "id": "TvDVNoB8wR3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}